---
title: Redis for PCF Architecture and Lifecycle
owner: London Services
---

<strong><%= modified_date %></strong>

Redis for PCF offers On-Demand, Dedicated-VM and Shared-VM plans. This section describes the architecture, lifecycle, and configurations of these plans, as well as networking information for the on-demand service.


## <a id ="architecture"></a>Redis for PCF Architecture for On-Demand Service Plan

### <a id="diagram1"></a> Architecture Diagram for On-Demand Plan

This diagram shows how the architecture of the service broker and On Demand plans and how the user's app binds to a Redis instance.

![On-Demand Architecture Diagram](on-demand-arch.png)

### <a id="on-demand"></a> On-Demand Service Plans
* These plans are Operator-configured and enabled. 
* Once enabled, App Developers can view the available plans in the marketplace and provision a Redis instance from that plan.
* You can disable any of the three on-demand plans in the plan's page in OpsManager. See descriptions of the three on-demand plans [here](minor-overview.html#service).
* The maximum number of instances is managed at by a per-plan and global quota. The maximum number of instances cannot surpass 50.
* Operators can update the plan settings, including the VM size, disk size and Redis configuration settings, after the plans have been created. **Operators should not downsize the VMs or disk size as this can cause data loss in pre-existing instances.**
* App Developers can update certain Redis configurations.
* Back ups are not available for On-Demand plans.


### <a id="config"></a> Configuration for On-Demand Service Plans

On-Demand plans are best fit for cache use cases.

For On-Demand Plans, certain Redis configurations can be set by the operator during plan configuration,
 and by the App Developer during instance provisioning. Other Redis configurations cannot be changed from the default.

 + Operator configurable Redis settings include: `timeout`, `tcp-keepalive`, `maxclients` and `lua scripting`. See the Operator Guide section of this documentation for more detail.
 + App-Developer configurable Redis settings include: `maxmemory-policy`, `notify-keyspace-events`,`slowlog-log-slower-than`,and `slowlog-max-len`. See the App Developer guide of this documentation for more detail.

#### Operator Notes for On-Demand Service Plans

* This plan enables Redis instances to be deployed on dedicated VMs. Instances can be deployed until they reach either an opertor-set per-plan quota or global quota.
* Instances are provisioned based on the [On-Demand Services SDK](http://docs.pivotal.io/on-demand-service-broker/) and service broker adapter associated with this plan.
* Any On-Demand plan can be disabled from the plan page in OpsManager.

#### Known Limitations for On-Demand Service Plans

Limitations with the current `On-Demand` Service include:

* Operators can update certain plan settings after the plans have been created. To ensure upgrades happen across all instances, set the 'upgrade instances' errand to 'on'.
If the Operator updates the VM size, disk size, or the Redis configuration settings (enabling Lua Scripting, max-clients, timeout and TCP keep-alive), these settings will be implemented in all instances already created. Operators should not downsize the VMs or disk size as this can cause data loss in pre-existing instances.

### <a id ="lifecycle"></a>Lifecycle for On-Demand Service Plan

Here is the lifecycle of Redis for PCF, from an operator installing the tile through an app developer using the service then an operator deleting the tile.

![On-Demand Lifecycle Diagram](Redis_timeline_demand.png)


## <a id="networks"></a>On-Demand Services and Networking

### <a id="bosh2"></a>BOSH 2.0 and the Service Network

<%= partial '../../redis/odb/service_networks' %>

### <a id ="architecture_networks"></a>Default Network and Service Network

Like other on-demand PCF services, on-demand Redis for PCF relies on the BOSH 2.0 ability to dynamically deploy VMs in a dedicated network. The on-demand service broker uses this capability to create single-tenant service instances in a dedicated service network.

<%= partial '../../redis/odb/on_demand_architecture' %>

The diagram below shows worker VMs in an on-demand service instance, such as RabbitMQ for PCF, running on a separate services network, while other components run on the default network.

![Architecture Diagram](ODB-architecture.png)

### <a id="network-rules"></a>Required Networking Rules for On-Demand Services

<%= partial '../../redis/odb/service_networks_table' %>


## <a id="arch-dedicated-shared"></a>Redis for PCF Architecture for Dedicated-VM and Shared-VM Service Plans

### <a id="diagram2"></a>Architecture Diagram for Shared and Dedicated Plans

This diagram shows how the architecture of the service broker and Shared-VM and Dedicated-VM plans and how the user's app binds to a Redis instance.

![Architecture Diagram](legacy-arch.png)

### <a id="shared-dedicated"></a> About Shared-VM and Dedicated-VM Service Plans

For Dedicated-VM and Shared-VM plans, Redis is configured with a `maxmemory-policy` of `no-eviction`. This policy means that once memory is full, the service will not evict any keys, and no write operations will be possible until memory becomes available. 

Persistence is configured for both `RDB` and `AOF`. The default maximum number of connections, maxclients, is set at 10000 but this number is adjusted by Redis according to the number of file handles available. 

Replication and event notification are not configured.

### <a id="shared-vm"></a> Shared-VM Service Plan

An instance of this plan provisions a single Redis process on a single **shared VM** that is suitable for workloads which do not require dedicated hardware.

* This plan deploys a Redis instance inside the service broker VM.
* You can disable this plan by setting the `Max instances limit` on the `Shared-VM plan` tab in OpsManager to be `0`.
* The maximum number of instances can be increased from the default 5 to a value of your choosing. If you increase the number of instances that can be run on this single VM, you should consider increasing the resources allocated to the VM. In particular RAM and CPU. You can overcommit to a certain extent, but may start to see performance degradations.
* You can also increase the maximum amount of RAM allocated to each Redis process (service instance) that is running on this VM
* If you decrease the service instance limit, any instances that are running where the count is now greater than the limit are not terminated. They are left to be removed naturally, until the total count drops below the new limit you cannot create any new instances. For example if you had a limit of 10 and all were used and reduced this to 8, the two instances will be left running until you terminate them yourself.



### <a id="dedicated-vm"></a> Dedicated-VM Service Plan

An instance of this plan, provisions a single Redis process, on a single **dedicated VM**, which is suitable for workloads that require isolation or dedicated hardware.

The following commands are enabled:

* `MONITOR`
* `SAVE`
* `BGSAVE`
* `BGREWRITEAOF`

Data persistence is enabled through the use of `RDB` and `AOF`.

The `maxmemory` value for the Redis process is set to be 45% of the RAM for that instance.

The persistent disk should be set to be at least the size of the RAM available to the VM or greater, in order to account for the final and temporary RDB file generated by the Redis background save.

* This plan deploys the operator-configured number of dedicated Redis VMs alongside the service broker VM.
* These instances are pre-provisioned during the deployment of the tile from OpsManager into a **pool**. The VMs are provisioned and configured with a Redis process ready to be used when an instance of the Dedicated-VM plan is requested.
* A default deployment will provision `5 instances` of the Dedicated-VM plan into the **pool**. This number can be increased on the `Resource Config` tab in Ops Manager, either in the initial deployment, or subsequently thereafter. The number of VMs **cannot** be decreased once deployed.
* When a user provisions an instance, it is marked as in use and taken out of the **pool**.
* When a user deprovisions an instance, the instance is cleansed of any data and configuration to restore it to a fresh state and placed back into the pool, ready to be used again.
* You can disable this plan by setting the number of instances of the `Dedicated node` job in Ops Manager to `0`.


### <a id="config2"></a> Configuration for Dedicated-VM and Shared-VM Service Plans

For Dedicated-VM and Shared-VM plans, the default Redis configurations cannot be changed. 
A sample `redis.conf` from a Dedicated-VM plan instance is provided [here] (redisconf.html).

+ Redis is configured with a `maxmemory-policy` of `no-eviction`. This policy means that when the memory is full, the service does
 not evict any keys or perform any write operations until memory becomes available.

+ Persistence is configured for both `RDB` and `AOF`.

+ The default maximum number of connections, `maxclients`, is set at 10000 but
this number is adjusted by Redis according to the number of file handles available.

+ Replication and event notification are not configured.

#### Operator Notes for the Shared-VM Plan

* This plan deploys a shared VM and a single service broker VM.
* This plan can be disabled by setting the `Max instances limit` on the `Shared-VM Plan` tab in OpsManager to be `0`.
* The maximum number of instances can be increased from the default 5 to a value of your choosing. If you increase the number of instances that can be run on this single VM, you should consider increasing the resources allocated to the VM. In particular RAM and CPU. You can overcommit to a certain extent, but may start to see performance degradations.
* You can also increase the maximum amount of RAM allocated to each Redis process (service instance) that is running on this VM
* If you decrease the service instance limit, any instances that are running where the count is now greater than the limit are not terminated. They are left to be removed naturally, until the total count drops below the new limit you cannot create any new instances. For example if you had a limit of 10 and all were used and reduced this to 8, the two instances will be left running until you terminate them yourself.

#### Known Limitations of the Shared-VM Plan

Limitations with the current `shared-vm` plan include:

* It cannot be scaled beyond a single virtual machine.
* The following commands are disabled: `CONFIG`, `MONITOR`, `SAVE`, `BGSAVE`,
  `SHUTDOWN`, `BGREWRITEAOF`, `SLAVEOF`, `DEBUG`, and `SYNC`.
* Constraining CPU and/or disk usage is not supported.
* The Shared-VM plan does not manage 'noisy neighbor' problems so it is not recommended for production apps.

#### Operator Notes for the Dedicated-VM Service Plan

* This plan deploys several dedicated Redis VMs and a single service broker VM.
* These instances are pre-provisioned during the deployment of the tile from OpsManager into a **pool**. The VMs are provisioned and configured with a Redis process ready to be used when an instance of the `dedicated-vm` plan is requested.
* A default deployment will provision `5 instances` of the `dedicated-vm` plan into the **pool**. This number can be increased on the `Resource Config` tab in Ops Manager, either in the initial deployment, or subsequently thereafter. The number of VMs **cannot** be decreased once deployed.
* When a user provisions an instance, it is marked as in use and taken out of the **pool**.
* When a user deprovisions an instance, the instance is cleansed of any data and configuration to restore it to a fresh state and placed back into the pool, ready to be used again.
* This plan can be disabled by setting the number of instances of the `Dedicated node` job in Ops Manager to `0`.

#### Known Limitations of the Dedicated-VM Service Plan

Limitations of the `dedicated-vm` plan include:

* No ability to change the Redis configuration. The `CONFIG` command is disabled.
* Cannot scale down the number of VMs on the plan once deployed.


### <a id="config2"></a> Configuration for Dedicated-VM and Shared-VM Service Plans

For Dedicated-VM and Shared-VM plans, the default Redis configurations cannot be changed.
A sample `redis.conf` from a Dedicated-VM plan instance is provided [here] (redisconf.html).

+ Redis is configured with a `maxmemory-policy` of `no-eviction`. This policy means that when the memory is full, the service does
 not evict any keys or perform any write operations until memory becomes available.

+ Persistence is configured for both `RDB` and `AOF`.

+ The default maximum number of connections, `maxclients`, is set at 10000 but
this number is adjusted by Redis according to the number of file handles available.

+ Replication and event notification are not configured.


### <a id="lifecycle-dedicated-shared"></a>Lifecycle for Dedicated-VM and Shared-VM Service Plans

Here is the lifecycle of Redis for PCF, from an operator installing the tile through an app developer using the service then an operator deleting the tile.

![Lifecycle Diagram](Redis_timeline_legacy.png)

